{"cells":[{"cell_type":"code","execution_count":23,"id":"cb096b5c-13b9-4160-8ab0-72da8dd662ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19896,"status":"ok","timestamp":1742766988211,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"},"user_tz":0},"id":"cb096b5c-13b9-4160-8ab0-72da8dd662ab","outputId":"dc61e49d-6d3f-43e8-960c-2f6684d36022"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["!pip install xgboost\n","from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline as ImbPipeline  # Use imbalanced-learn's Pipeline\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","\n","# Step 1: Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Define the correct paths to your dataset\n","train_path = \"/content/drive/MyDrive/fraudTrain.csv\"\n","test_path = \"/content/drive/MyDrive/fraudTest.csv\"\n","\n","# Load training data\n","df_train= pd.read_csv(train_path)\n","# Load training data\n","df_test= pd.read_csv(test_path)\n"]},{"cell_type":"code","execution_count":24,"id":"79daa43b-224b-4ab1-9e02-d81e2541774b","metadata":{"executionInfo":{"elapsed":245,"status":"ok","timestamp":1742767012825,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"},"user_tz":0},"id":"79daa43b-224b-4ab1-9e02-d81e2541774b"},"outputs":[],"source":["# Drop unnecessary columns\n","df_train.drop(columns=['Unnamed: 0', 'trans_num', 'trans_date_trans_time', 'dob','state'], inplace=True)\n","df_test.drop(columns=['Unnamed: 0', 'trans_num', 'trans_date_trans_time', 'dob','state'], inplace=True)"]},{"cell_type":"code","execution_count":25,"id":"288619f6-0167-432f-b875-cfe145b7b617","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1742767013999,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"},"user_tz":0},"id":"288619f6-0167-432f-b875-cfe145b7b617"},"outputs":[],"source":["# Separate target variable before transformation\n","y_train = df_train.pop('is_fraud')\n","y_test = df_test.pop('is_fraud')"]},{"cell_type":"code","execution_count":26,"id":"77c3a10f-f2b4-476e-937f-629c73a3bbfa","metadata":{"executionInfo":{"elapsed":7000,"status":"ok","timestamp":1742767022244,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"},"user_tz":0},"id":"77c3a10f-f2b4-476e-937f-629c73a3bbfa"},"outputs":[],"source":["# Define categorical and numerical columns\n","categorical_columns = ['merchant', 'category', 'gender', 'city', 'job']\n","numerical_columns = ['amt', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long']\n","\n","# Preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), categorical_columns),  # Ensure dense output\n","        ('num', Pipeline([\n","            ('imputer', SimpleImputer(strategy='median')),\n","            ('scaler', StandardScaler())\n","        ]), numerical_columns)\n","    ]\n",")\n","\n","# Split the data into train and test (Stratified split to maintain the imbalance ratio)\n","X_train, X_test, y_train, y_test = train_test_split(df_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n","\n","# Apply preprocessing to the training data\n","X_train_preprocessed = preprocessor.fit_transform(X_train)\n","X_test_preprocessed = preprocessor.transform(X_test)  # Apply the same transformations to test data"]},{"cell_type":"code","execution_count":27,"id":"ZEdDGLsexHKF","metadata":{"executionInfo":{"elapsed":4854,"status":"ok","timestamp":1742767029956,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"},"user_tz":0},"id":"ZEdDGLsexHKF"},"outputs":[],"source":["# Apply SMOTE after preprocessing but before model training\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)"]},{"cell_type":"code","execution_count":28,"id":"d40a7ea9-8f4f-4a87-91be-b5db41eaf707","metadata":{"id":"d40a7ea9-8f4f-4a87-91be-b5db41eaf707","executionInfo":{"status":"ok","timestamp":1742767032739,"user_tz":0,"elapsed":4,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"}}},"outputs":[],"source":["# Initialize classifiers\n","models = {\n","    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n","    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n","    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n","}"]},{"cell_type":"code","execution_count":29,"id":"0wOzh0MYBfJc","metadata":{"id":"0wOzh0MYBfJc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742774549901,"user_tz":0,"elapsed":7511409,"user":{"displayName":"Lulu Hsu","userId":"11681570293069538122"}},"outputId":"26ffb852-fb0e-4d83-c594-1f6e715df0c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training Random Forest...\n","Performance of Random Forest at default threshold (0.5):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00    257834\n","           1       0.83      0.65      0.73      1501\n","\n","    accuracy                           1.00    259335\n","   macro avg       0.91      0.82      0.86    259335\n","weighted avg       1.00      1.00      1.00    259335\n","\n","Performance of Random Forest at custom threshold (0.3):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00    257834\n","           1       0.68      0.77      0.73      1501\n","\n","    accuracy                           1.00    259335\n","   macro avg       0.84      0.89      0.86    259335\n","weighted avg       1.00      1.00      1.00    259335\n","\n","\n","Training Gradient Boosting...\n","Performance of Gradient Boosting at default threshold (0.5):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99    257834\n","           1       0.21      0.87      0.33      1501\n","\n","    accuracy                           0.98    259335\n","   macro avg       0.60      0.93      0.66    259335\n","weighted avg       0.99      0.98      0.99    259335\n","\n","Performance of Gradient Boosting at custom threshold (0.3):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97    257834\n","           1       0.08      0.93      0.15      1501\n","\n","    accuracy                           0.94    259335\n","   macro avg       0.54      0.94      0.56    259335\n","weighted avg       0.99      0.94      0.96    259335\n","\n","\n","Training XGBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [00:01:20] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Performance of XGBoost at default threshold (0.5):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00    257834\n","           1       0.43      0.85      0.57      1501\n","\n","    accuracy                           0.99    259335\n","   macro avg       0.72      0.92      0.79    259335\n","weighted avg       1.00      0.99      0.99    259335\n","\n","Performance of XGBoost at custom threshold (0.3):\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99    257834\n","           1       0.25      0.91      0.39      1501\n","\n","    accuracy                           0.98    259335\n","   macro avg       0.62      0.94      0.69    259335\n","weighted avg       1.00      0.98      0.99    259335\n","\n"]}],"source":["# Train and evaluate each model\n","for model_name, model in models.items():\n","    print(f\"\\nTraining {model_name}...\")\n","    model.fit(X_train_resampled, y_train_resampled)\n","\n","    # Get probabilities for the positive class (fraud)\n","    y_prob = model.predict_proba(X_test_preprocessed)[:, 1]\n","\n","    # Use default 0.5 threshold\n","    y_pred_default = (y_prob >= 0.5).astype(int)\n","    print(f\"Performance of {model_name} at default threshold (0.5):\")\n","    print(classification_report(y_test, y_pred_default))\n","\n","    # Custom threshold (0.3)\n","    custom_threshold = 0.3\n","    y_pred_custom = (y_prob >= custom_threshold).astype(int)\n","    print(f\"Performance of {model_name} at custom threshold (0.3):\")\n","    print(classification_report(y_test, y_pred_custom))"]},{"cell_type":"code","execution_count":null,"id":"a7484508-7b18-4416-a421-24795b37b45f","metadata":{"id":"a7484508-7b18-4416-a421-24795b37b45f"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"13oQMHEhnstke-vGhDzz13mXy0-UCTSns","timestamp":1742778783439},{"file_id":"1dRSpPX9p2hBsRKAsFd9HsmAPlveHDrLe","timestamp":1742655664640}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"}},"nbformat":4,"nbformat_minor":5}